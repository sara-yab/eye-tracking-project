{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f6a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sarayabesi/Documents/research-poly/eye-tracker-project/data_extraction\n",
      "---------------\n",
      "here: p101-1\n",
      "here: p101-2\n",
      "here: p101-3\n",
      "here: p101-4\n",
      "here: p101-5\n",
      "here: p101-6\n",
      "---------------\n",
      "here: p102-1\n",
      "here: p102-2\n",
      "here: p102-3\n",
      "here: p102-4\n",
      "here: p102-5\n",
      "here: p102-6\n",
      "---------------\n",
      "here: p103-1\n",
      "here: p103-2\n",
      "here: p103-3\n",
      "here: p103-4\n",
      "here: p103-5\n",
      "here: p103-6\n",
      "---------------\n",
      "here: p104-1\n",
      "here: p104-2\n",
      "here: p104-3\n",
      "here: p104-4\n",
      "here: p104-5\n",
      "here: p104-6\n",
      "---------------\n",
      "here: p105-1\n",
      "here: p105-2\n",
      "here: p105-3\n",
      "here: p105-4\n",
      "here: p105-5\n",
      "here: p105-6\n",
      "---------------\n",
      "here: p106-1\n",
      "here: p106-2\n",
      "here: p106-3\n",
      "here: p106-4\n",
      "here: p106-5\n",
      "here: p106-6\n",
      "---------------\n",
      "here: p107-1\n",
      "here: p107-2\n",
      "here: p107-3\n",
      "here: p107-4\n",
      "here: p107-5\n",
      "here: p107-6\n",
      "---------------\n",
      "here: p108-1\n",
      "here: p108-2\n",
      "here: p108-3\n",
      "here: p108-4\n",
      "here: p108-5\n",
      "here: p108-6\n",
      "---------------\n",
      "here: p109-1\n",
      "here: p109-2\n",
      "here: p109-3\n",
      "here: p109-4\n",
      "here: p109-5\n",
      "here: p109-6\n",
      "---------------\n",
      "here: p110-1\n",
      "here: p110-2\n",
      "here: p110-3\n",
      "here: p110-4\n",
      "here: p110-5\n",
      "here: p110-6\n",
      "---------------\n",
      "here: p111-1\n",
      "here: p111-2\n",
      "here: p111-3\n",
      "here: p111-4\n",
      "here: p111-5\n",
      "here: p111-6\n",
      "---------------\n",
      "here: p112-1\n",
      "here: p112-2\n",
      "here: p112-3\n",
      "here: p112-4\n",
      "here: p112-5\n",
      "here: p112-6\n",
      "---------------\n",
      "here: p113-1\n",
      "here: p113-2\n",
      "here: p113-3\n",
      "here: p113-4\n",
      "here: p113-5\n",
      "here: p113-6\n",
      "---------------\n",
      "here: p114-1\n",
      "here: p114-2\n",
      "here: p114-3\n",
      "here: p114-4\n",
      "here: p114-5\n",
      "here: p114-6\n",
      "---------------\n",
      "here: p115-1\n",
      "here: p115-2\n",
      "here: p115-3\n",
      "here: p115-4\n",
      "here: p115-5\n",
      "here: p115-6\n",
      "---------------\n",
      "here: p116-1\n",
      "here: p116-2\n",
      "here: p116-3\n",
      "here: p116-4\n",
      "here: p116-5\n",
      "here: p116-6\n",
      "---------------\n",
      "here: p117-1\n",
      "here: p117-2\n",
      "here: p117-3\n",
      "here: p117-4\n",
      "here: p117-5\n",
      "here: p117-6\n",
      "---------------\n",
      "here: p118-1\n",
      "here: p118-2\n",
      "here: p118-3\n",
      "here: p118-4\n",
      "here: p118-5\n",
      "here: p118-6\n",
      "---------------\n",
      "here: p119-1\n",
      "here: p119-2\n",
      "here: p119-3\n",
      "here: p119-4\n",
      "here: p119-5\n",
      "here: p119-6\n",
      "---------------\n",
      "here: p120-1\n",
      "here: p120-2\n",
      "here: p120-3\n",
      "here: p120-4\n",
      "here: p120-5\n",
      "here: p120-6\n",
      "---------------\n",
      "here: p121-1\n",
      "here: p121-2\n",
      "here: p121-3\n",
      "here: p121-4\n",
      "here: p121-5\n",
      "here: p121-6\n",
      "---------------\n",
      "here: p122-1\n",
      "here: p122-2\n",
      "here: p122-3\n",
      "here: p122-4\n",
      "here: p122-5\n",
      "here: p122-6\n",
      "---------------\n",
      "here: p123-1\n",
      "here: p123-2\n",
      "here: p123-3\n",
      "here: p123-4\n",
      "here: p123-5\n",
      "here: p123-6\n",
      "---------------\n",
      "here: p124-1\n",
      "here: p124-2\n",
      "here: p124-3\n",
      "here: p124-4\n",
      "here: p124-5\n",
      "here: p124-6\n",
      "---------------\n",
      "here: p125-1\n",
      "here: p125-2\n",
      "here: p125-3\n",
      "here: p125-4\n",
      "here: p125-5\n",
      "here: p125-6\n",
      "---------------\n",
      "here: p126-1\n",
      "here: p126-2\n",
      "here: p126-3\n",
      "here: p126-4\n",
      "here: p126-5\n",
      "here: p126-6\n",
      "---------------\n",
      "here: p127-1\n",
      "here: p127-2\n",
      "here: p127-3\n",
      "here: p127-4\n",
      "here: p127-5\n",
      "here: p127-6\n",
      "---------------\n",
      "here: p129-1\n",
      "here: p129-2\n",
      "here: p129-3\n",
      "here: p129-4\n",
      "here: p129-5\n",
      "here: p129-6\n",
      "---------------\n",
      "here: p130-1\n",
      "here: p130-2\n",
      "here: p130-3\n",
      "here: p130-4\n",
      "here: p130-5\n",
      "here: p130-6\n",
      "---------------\n",
      "here: p131-1\n",
      "here: p131-2\n",
      "here: p131-3\n",
      "here: p131-4\n",
      "here: p131-5\n",
      "here: p131-6\n",
      "---------------\n",
      "here: p132-1\n",
      "here: p132-2\n",
      "here: p132-3\n",
      "here: p132-4\n",
      "here: p132-5\n",
      "here: p132-6\n",
      "---------------\n",
      "here: p133-1\n",
      "here: p133-2\n",
      "here: p133-3\n",
      "here: p133-4\n",
      "here: p133-5\n",
      "here: p133-6\n",
      "---------------\n",
      "here: p135-1\n",
      "here: p135-2\n",
      "here: p135-3\n",
      "here: p135-4\n",
      "here: p135-5\n",
      "here: p135-6\n",
      "---------------\n",
      "here: p136-1\n",
      "here: p136-2\n",
      "here: p136-3\n",
      "here: p136-4\n",
      "here: p136-5\n",
      "here: p136-6\n",
      "---------------\n",
      "here: p137-1\n",
      "here: p137-2\n",
      "here: p137-3\n",
      "here: p137-4\n",
      "here: p137-5\n",
      "here: p137-6\n",
      "---------------\n",
      "here: p139-1\n",
      "here: p139-2\n",
      "here: p139-3\n",
      "here: p139-4\n",
      "here: p139-5\n",
      "here: p139-6\n",
      "---------------\n",
      "here: p140-1\n",
      "here: p140-2\n",
      "here: p140-3\n",
      "here: p140-4\n",
      "here: p140-5\n",
      "here: p140-6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "# Get the current working directory\n",
    "main_dir = os.getcwd()\n",
    "print(main_dir)\n",
    "\n",
    "\n",
    "# Define the user IDs to skip\n",
    "skip_user_ids = {128, 134, 138}\n",
    "\n",
    "# Function to get file names in a directory\n",
    "def get_file_names(directory):\n",
    "        file_names = []\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                file_names.append(file)\n",
    "        return sorted(file_names)\n",
    "\n",
    "\n",
    "# Loop through user IDs from 101 to 140\n",
    "for user_id in range(101, 141):\n",
    "    if user_id in skip_user_ids:\n",
    "        continue\n",
    "\n",
    "    user_id_str = str(user_id)\n",
    "    \n",
    "    # Read java info file\n",
    "    java_data = pd.read_excel(os.path.join(main_dir, 'java-info.xlsx'))\n",
    "    java_data_columns = java_data.columns\n",
    "    print('---------------')\n",
    "\n",
    "    user_dir = os.path.join(main_dir, 'raw_data', f'p{user_id_str}')\n",
    "    \n",
    "    file_names = get_file_names(user_dir)\n",
    "   \n",
    "    # Read user info data\n",
    "    user_data = pd.read_csv(os.path.join(user_dir, 'info.csv'))\n",
    "    \n",
    "   \n",
    "    folder_data = {}\n",
    "    for file_name in file_names:\n",
    "        if (file_name.endswith(\".xlsx\") or file_name.endswith(\".csv\")) & (\"info\" not in file_name):\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                print('here:', file_name.replace(\".csv\", \"\"))\n",
    "                fix_data = pd.read_csv(os.path.join(user_dir, file_name))\n",
    "                fix_data['start'] = fix_data['duration'].shift(fill_value=1).cumsum()\n",
    "                folder_data[file_name.replace(\".csv\", \"\")] = fix_data\n",
    "\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'PID','Task', 'bug_number', 'AOI','AOI_No', 'Accuracy_0_1', 'Accept_Y_N', 'FxCount', 'FxRate', 'TotalFixationTime', 'AvgFixationDuration', 'FirstFixation'\n",
    "    ])\n",
    "    \n",
    "    for i, (key, value) in enumerate(folder_data.items()):\n",
    "        fixation_data = folder_data[key]\n",
    "        task_number = 'T' + key[key.index(\"-\") + 1]\n",
    "        bug_number = user_data['order'][i]\n",
    "        bug_name = f'Bug-{bug_number}.txt'\n",
    "        bug_general = java_data[(bug_number >= java_data['min']) & (bug_number <= java_data['max'])].iloc[0]\n",
    "        is_accepted = user_data['trust'][i]\n",
    "        is_correct = bug_general['quality']\n",
    "        total_fix_count = len(fixation_data)\n",
    "        \n",
    "     \n",
    "        \n",
    "        # Construct AOI1: Bug report file\n",
    "        fix_data_a1 = fixation_data[(fixation_data['fixation_target'] == str(bug_name))]\n",
    "        total_fix_a1 = fix_data_a1['duration'].sum()\n",
    "        avg_fix_a1 = 'NA' if len(fix_data_a1) == 0 else total_fix_a1 / len(fix_data_a1)\n",
    "        first_fix_a1 = 'NA' if len(fix_data_a1) == 0 else fix_data_a1.iloc[0]['start']\n",
    "\n",
    "        aoi_a1 = pd.DataFrame({\n",
    "            'PID': user_id, 'Task': task_number, \n",
    "            'bug_number': bug_number, 'AOI': 'BugReport', 'AOI_No': 'A1', 'Accuracy_0_1': is_correct,\n",
    "            'Accept_Y_N': is_accepted, 'FxCount': len(fix_data_a1), \n",
    "            'TotalFixationTime': total_fix_a1, 'FxRate': len(fix_data_a1) / total_fix_count, \n",
    "            'AvgFixationDuration': avg_fix_a1, 'FirstFixation': first_fix_a1\n",
    "        }, index=[None])\n",
    "\n",
    "        # Construct AOI2: Class in source code\n",
    "        fix_data_a2 = fixation_data[(fixation_data['fixation_target'] == (bug_general['src_class'] + '.java'))]\n",
    "        total_fix_a2 = fix_data_a2['duration'].sum()\n",
    "        avg_fix_a2 = 'NA' if len(fix_data_a2) == 0 else total_fix_a2 / len(fix_data_a2)\n",
    "        first_fix_a2 = 'NA' if len(fix_data_a2) == 0 else fix_data_a2.iloc[0]['start']\n",
    "\n",
    "        aoi_a2 = pd.DataFrame({\n",
    "            'PID': user_id, 'Task': task_number, 'bug_number': bug_number, 'AOI': 'RelevantCodeClass', 'AOI_No': 'A2', 'Accuracy_0_1': is_correct, \n",
    "             'Accept_Y_N': is_accepted, 'FxCount': len(fix_data_a2), \n",
    "            'TotalFixationTime': total_fix_a2, 'FxRate': len(fix_data_a2) / total_fix_count, \n",
    "            'AvgFixationDuration': avg_fix_a2, 'FirstFixation': first_fix_a2\n",
    "        }, index=[None])\n",
    "\n",
    "        # Construct AOI3: Method in source code(inside class of source code)\n",
    "        fix_data_a3 = fix_data_a2[(fix_data_a2['source_file_line'] >= bug_general['src_method_start']) & \n",
    "                                   (fix_data_a2['source_file_line'] <= bug_general['src_method_end'])]\n",
    "        total_fix_a3 = fix_data_a3['duration'].sum()\n",
    "        avg_fix_a3 = 'NA' if len(fix_data_a3) == 0 else total_fix_a3 / len(fix_data_a3)\n",
    "        first_fix_a3 = 'NA' if len(fix_data_a3) == 0 else fix_data_a3.iloc[0]['start']\n",
    "\n",
    "        aoi_a3 = pd.DataFrame({\n",
    "            'PID': user_id, 'Task': task_number,'bug_number': bug_number, 'AOI': 'RelevantCodeMethod', 'AOI_No': 'A3', 'Accuracy_0_1': is_correct, \n",
    "             'Accept_Y_N': is_accepted,  'FxCount': len(fix_data_a3), 'TotalFixationTime': total_fix_a3, 'FxRate': len(fix_data_a3) / total_fix_count, \n",
    "            'AvgFixationDuration': avg_fix_a3, 'FirstFixation': first_fix_a3\n",
    "        }, index=[None])\n",
    "        \n",
    "        \n",
    "        # Construct A4: Test class\n",
    "        fix_data_a4 = fixation_data[(fixation_data['fixation_target'] == (bug_general['test_class']+'.java'))]\n",
    "        total_fix_a4 = fix_data_a4['duration'].sum()\n",
    "        avg_fix_a4 = 'NA' if len(fix_data_a4) == 0 else total_fix_a4 / len(fix_data_a4)\n",
    "        first_fix_a4 = 'NA' if len(fix_data_a4) == 0 else fix_data_a4.iloc[0]['start']\n",
    "\n",
    "        aoi_a4 = pd.DataFrame({'PID':user_id,'Task':task_number, 'bug_number':bug_number,'AOI': 'RelevantTestClass',\n",
    "                                'AOI_No': 'A4','Accuracy_0_1':is_correct,'Accept_Y_N':is_accepted,\n",
    "                               'FxCount':len(fix_data_a4),'TotalFixationTime':total_fix_a4,\n",
    "                                'FxRate':len(fix_data_a4)/total_fix_count,\n",
    "                                'AvgFixationDuration':avg_fix_a4,'FirstFixation':first_fix_a4\n",
    "                                }, index=[None])\n",
    "\n",
    "        \n",
    "        # Construct A5: Test method(inside test class)\n",
    "        fix_data_a5 = fix_data_a4[(fix_data_a4['source_file_line'] >= bug_general['test_method_start']) &\n",
    "                                   (fix_data_a4['source_file_line'] <= bug_general['test_method_end'])]\n",
    "        total_fix_a5 = fix_data_a5['duration'].sum()\n",
    "        avg_fix_a5 = 'NA' if len(fix_data_a5) == 0 else total_fix_a5 / len(fix_data_a5)\n",
    "        first_fix_a5 = 'NA' if len(fix_data_a5) == 0 else fix_data_a5.iloc[0]['start']\n",
    "\n",
    "        aoi_a5 = pd.DataFrame({'PID':user_id,'Task':task_number, 'bug_number':bug_number, 'AOI': 'RelevantTestMethod',\n",
    "                               'AOI_No': 'A5','Accuracy_0_1':is_correct,'Accept_Y_N': is_accepted,\n",
    "                               'FxCount':len(fix_data_a5),'TotalFixationTime':total_fix_a5,\n",
    "                               'FxRate':len(fix_data_a5)/total_fix_count,\n",
    "                                'AvgFixationDuration':avg_fix_a5,'FirstFixation':first_fix_a5\n",
    "                                }, index=[None])\n",
    "\n",
    "        # Construct AOI6: Other files\n",
    "        fix_data_a6 = filtered_data = fixation_data[~((fixation_data['fixation_target'] == str(bug_name)) |\n",
    "                                    (fixation_data['fixation_target'] == (bug_general['src_class'] + '.java')) |\n",
    "                                    (fixation_data['fixation_target'] == (bug_general['test_class'] + '.java')))]\n",
    "        total_fix_a6 = fix_data_a6['duration'].sum()\n",
    "        avg_fix_a6 = 'NA' if len(fix_data_a6) == 0 else total_fix_a6 / len(fix_data_a6)\n",
    "        first_fix_a6 = 'NA' if len(fix_data_a6) == 0 else fix_data_a6.iloc[0]['start']\n",
    "\n",
    "\n",
    "        aoi_a6 = pd.DataFrame({'PID':user_id,'Task':task_number, 'bug_number':bug_number,'AOI': 'Others',\n",
    "                               'AOI_No': 'A6', 'Accuracy_0_1':is_correct,\n",
    "                               'Accept_Y_N': is_accepted,\n",
    "                               'FxCount':len(fix_data_a6),'TotalFixationTime':total_fix_a6,\n",
    "                               'FxRate':len(fix_data_a6)/total_fix_count,\n",
    "                               'AvgFixationDuration':avg_fix_a6,'FirstFixation':first_fix_a6\n",
    "                               }, index=[None])\n",
    "\n",
    "        # Construct AOI0: All fixations in all files\n",
    "        total_fix_a7 = fixation_data['duration'].sum()\n",
    "        avg_fix_a7 = 'NA' if total_fix_count == 0 else total_fix_a7 / total_fix_count\n",
    "\n",
    "\n",
    "        aoi_all = pd.DataFrame({'PID':user_id,'Task':task_number, 'bug_number':bug_number,'AOI': 'Total',\n",
    "                                  'AOI_No': 'A0','Accuracy_0_1':is_correct,'Accept_Y_N': is_accepted,'FxCount':total_fix_count,\n",
    "                                'TotalFixationTime':total_fix_a7,\n",
    "                                  'FxRate':1,\n",
    "                                   'AvgFixationDuration':avg_fix_a7,'FirstFixation':'NA'\n",
    "                                  }, index=[None])\n",
    "    \n",
    "\n",
    "        frames = [df, aoi_all, aoi_a1, aoi_a2, aoi_a3, aoi_a4, aoi_a5, aoi_a6]\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    folder_path = \"generated_fixations/\"\n",
    "    file_name = f'p{user_id_str}_fixations.csv'\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Save the DataFrame to a CSV file in the specified folder\n",
    "    df.to_csv(os.path.join(folder_path, file_name), index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a295b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully in the generated_fixations folder.\n"
     ]
    }
   ],
   "source": [
    "# merge fixation generated excel files and sort them\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path where files should be saved\n",
    "folder_path = os.path.join(main_dir, 'generated_fixations')\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Create an empty list to store individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each CSV file and append its DataFrame to the list\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "initial_df = pd.concat(dataframes)\n",
    "\n",
    "# Reset the index of the concatenated DataFrame\n",
    "initial_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save initial dataframe with all the users and data\n",
    "initial_df.to_csv(os.path.join(folder_path, 'all_fixations.csv'), index=False, na_rep='NA')\n",
    "\n",
    "# Sort the concatenated DataFrame\n",
    "sorted_df = initial_df.sort_values(by=['PID', 'Task'])\n",
    "\n",
    "# Save the sorted DataFrame\n",
    "sorted_df.to_csv(os.path.join(folder_path, 'all_fixations_sorted.csv'), index=False, na_rep='NA')\n",
    "\n",
    "print(\"Files saved successfully in the generated_fixations folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb67b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a3832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
